# 동화책 API 백엔드 - 구현 워크쓰루

## 요약

External API Specification v2.0을 따르는 어린이 동화책 생성용 FastAPI 백엔드 서버를 성공적으로 구현했습니다. 서버는 필드별 STT, 비동기 동화 생성 파이프라인 (LLM → ComfyUI 이미지 → TTS), SSE 진행상황 추적, 파일 다운로드를 제공합니다.

## 구축된 내용

### 핵심 서버 (`server.py`)
6개의 엔드포인트를 가진 FastAPI 애플리케이션:
- `GET /` - 헬스 체크
- `POST /api/stt/field` - Whisper를 사용한 필드별 음성-텍스트 변환
- `POST /api/runs` - 동화 생성 실행 생성 (즉시 run_id 반환)
- `GET /api/runs/{run_id}` - 실행 상태 및 진행상황 조회
- `GET /api/runs/{run_id}/events` - 실시간 업데이트를 위한 SSE 이벤트 스트림
- `GET /api/runs/{run_id}/images/{filename}` - 생성된 이미지 다운로드
- `GET /api/runs/{run_id}/audio/{filename}` - 생성된 오디오 다운로드

### 상태 관리 ([run_manager.py](file:///c:/Users/user/Desktop/make_story/run_manager.py))
- SSE 이벤트 큐를 갖춘 인메모리 실행 상태 추적
- 출력 디렉토리 관리 (`outputs/{run_id}/`)
- 가장 오래된 출력 자동 삭제 (최근 100개 유지)
- 진행 표시기: `ready_max_page`, `ready_max_audio_page`

### 파이프라인 컴포넌트

#### [STT 모듈](file:///c:/Users/user/Desktop/make_story/pipeline/stt.py)
- 음성 인식을 위한 OpenAI Whisper 통합
- 시대/장소/등장인물/주제를 위한 필드별 파싱
- 신뢰도 점수 계산

#### [이미지 생성](file:///c:/Users/user/Desktop/make_story/pipeline/image_gen.py)
- ComfyUI HTTP API 통합
- `make_panel.json` 템플릿에서 워크플로우 수정
- 표지용 랜덤 시드, 패널 1-4는 재사용 시드
- 프롬프트 앞에 "watercolor painting, children's book illustration" 자동 추가
- 이미지 다운로드 및 저장

#### [TTS 생성](file:///c:/Users/user/Desktop/make_story/pipeline/tts_gen.py)
- 기존 `run_tts.py` 로직 래핑
- M1 음성, 한국어
- `page_0.wav`부터 `page_4.wav`까지 생성

#### [스토리 파이프라인](file:///c:/Users/user/Desktop/make_story/pipeline/story_pipeline.py)
- 모든 단계를 조율하는 비동기 오케스트레이터:
  1. LLM - 기존 `run_story.py`를 통한 스토리 생성
  2. COVER - 표지 이미지 생성
  3. PANEL_1-4 - 패널 이미지 생성
  4. TTS - 모든 페이지에 대한 오디오 생성
- 단계 진행 추적
- 각 단계에서 SSE 이벤트 발생
- FAILED 상태로 에러 처리

### API 모델 ([models.py](file:///c:/Users/user/Desktop/make_story/models.py))
타입 안정성을 위한 Pydantic 모델:
- 요청/응답 스키마
- Status 열거형: `QUEUED | RUNNING | DONE | FAILED`
- Stage 열거형: `LLM | COVER | PANEL_1 | PANEL_2 | PANEL_3 | PANEL_4 | TTS`

## 테스트 결과

### 스모크 테스트 ([test_smoke.py](file:///c:/Users/user/Desktop/make_story/test_smoke.py))

모든 테스트가 성공적으로 통과했습니다:

✓ **헬스 체크** - 서버가 http://127.0.0.1:8000 에서 응답
✓ **실행 생성** - `POST /api/runs`가 201과 유효한 run_id 반환
✓ **상태 조회** - `GET /api/runs/{run_id}`가 적절한 상태 구조 반환

샘플 출력:
```
============================================================
동화책 API 스모크 테스트
============================================================
헬스 엔드포인트 테스트 중...
✓ 헬스 체크 통과

실행 생성 테스트 중...
✓ 실행 생성됨: bca4e716dbe642fe99ca2a5dd94450ef

bca4e716dbe642fe99ca2a5dd94450ef에 대한 실행 상태 조회 테스트 중...
✓ 실행 상태: RUNNING / LLM
  준비된 페이지: -1
  준비된 오디오: -1

============================================================
모든 스모크 테스트 통과! ✓
============================================================
```

## 실행 방법

### 1. 종속성 설치
```powershell
cd c:\Users\user\Desktop\make_story
.\venv\Scripts\activate
pip install fastapi uvicorn[standard] openai-whisper python-multipart sse-starlette requests
```

### 2. 서버 시작
```powershell
uvicorn server:app --host 127.0.0.1 --port 8000 --reload
```

서버가 http://127.0.0.1:8000 에서 사용 가능합니다

### 3. 동화 생성
```powershell
curl -X POST http://127.0.0.1:8000/api/runs `
  -H "Content-Type: application/json" `
  -d '{\"era_ko\":\"현대\",\"place_ko\":\"숲\",\"characters_ko\":\"토끼\",\"topic_ko\":\"우정\"}'
```

반환값:
```json
{"run_id": "bca4e716dbe642fe99ca2a5dd94450ef"}
```

### 4. 진행상황 모니터링
**상태 조회:**
```powershell
curl http://127.0.0.1:8000/api/runs/{run_id}
```

**이벤트 스트리밍 (SSE):**
```powershell
curl http://127.0.0.1:8000/api/runs/{run_id}/events
```

### 5. 결과 다운로드
**이미지:**
```powershell
curl http://127.0.0.1:8000/api/runs/{run_id}/images/cover.png -o cover.png
curl http://127.0.0.1:8000/api/runs/{run_id}/images/panel_1.png -o panel_1.png
```

**오디오:**
```powershell
curl http://127.0.0.1:8000/api/runs/{run_id}/audio/page_0.wav -o page_0.wav
```

## 중요 참고사항

### 사전 요구사항
- **ComfyUI가 실행 중이어야 함** - 이미지 생성을 위해 http://127.0.0.1:8188 에서
- **LLM 모델**이 `llm_model/Qwen3-14B-Q8_0.gguf`에 있어야 함
- **Supertonic TTS 에셋**이 `supertonic/` 디렉토리에 있어야 함

### 첫 번째 STT 사용
첫 번째 STT 요청 시 Whisper "base" 모델(~140MB)을 다운로드합니다. 이는 일회성 다운로드입니다.

### 알려진 제한사항
1. **영구 저장소 없음** - 실행 상태는 인메모리만 (서버 재시작 시 손실)
2. **ComfyUI 종속성** - 서버는 ComfyUI가 미리 시작되어 있어야 함
3. **단일 스레드 파이프라인** - 각 실행은 순차적으로 처리됨
4. **인증 없음** - API가 공개되어 있음 (사양에 따름)

## 파일 구조

```
make_story/
├── server.py                    # 메인 FastAPI 애플리케이션
├── models.py                    # Pydantic API 모델
├── run_manager.py              # 실행 상태 & 이벤트 관리
├── pipeline/
│   ├── __init__.py
│   ├── stt.py                  # Whisper STT
│   ├── image_gen.py            # ComfyUI 통합
│   ├── tts_gen.py              # TTS 래퍼
│   └── story_pipeline.py       # 비동기 오케스트레이터
├── test_smoke.py               # 스모크 테스트
├── make_panel.json             # ComfyUI 워크플로우 템플릿
├── outputs/                    # 생성된 출력 (자동 생성)
│   └── {run_id}/
│       ├── cover.png
│       ├── panel_1.png ... panel_4.png
│       └── page_0.wav ... page_4.wav
└── requirements.txt            # 새 종속성으로 업데이트됨
```

## 작동하는 기능

✅ 6개 API 엔드포인트 모두 구현 및 테스트됨
✅ run_id를 사용한 비동기 백그라운드 처리
✅ 상태/단계 진행 추적
✅ SSE 이벤트 스트리밍
✅ 이미지 및 오디오 파일 다운로드
✅ 오래된 출력 자동 정리 (100개 제한)
✅ Whisper를 사용한 필드별 STT
✅ 기존 LLM 파이프라인과의 통합
✅ 시드 관리를 갖춘 ComfyUI 이미지 생성
✅ M1 음성을 사용한 TTS 생성

## 다음 단계 (필요시)

1. **영구 저장소 추가** - 실행 지속성을 위해 SQLite 또는 파일 기반 상태 사용
2. **ComfyUI 런처 추가** - ComfyUI가 실행 중이 아니면 자동 시작
3. **요청 검증 추가** - 더 강력한 입력 검증
4. **속도 제한 추가** - 남용 방지
5. **인증 추가** - 배포 시 필요한 경우
6. **로깅 추가** - 디버깅을 위한 구조화된 로깅
7. **메트릭 추가** - API 사용 및 성능 추적

